{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import logging as log\n",
    "from stompy import utils\n",
    "from stompy import memoize\n",
    "import xarray as xr\n",
    "from matplotlib import colors\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'postprocess_v00' from '/home/rusty/src/microplastic_sfbay/postprocess/postprocess_v00.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stompy.grid import unstructured_grid\n",
    "six.moves.reload_module(unstructured_grid)\n",
    "import postprocess_v00 as post\n",
    "six.moves.reload_module(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_fn=\"/opt2/sfb_ocean/suntans/runs/merged_018_20171227/ptm_average.nc_0000.nc\"  \n",
    "grid=post.grid_from_ptm_hydro(grid_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process one month chunks\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir=\"processed\"\n",
    "os.path.exists(out_dir) or os.makedirs(out_dir)\n",
    "    \n",
    "def process_batch(ptm_runs,\n",
    "                  time_range,\n",
    "                  patterns,\n",
    "                  z_ranges,\n",
    "                  max_age_days=15,\n",
    "                  version='v05'):\n",
    "    # v03: shift to particles/m3 units (in sync with change in postprocess_v00).\n",
    "    #   to speed things up, simply adjust v02 output if that exists.\n",
    "    # v04: should be same as v03, but is recomputed, not just post-hoc scaled.\n",
    "    # v05: start scaling up stormwater, too.\n",
    "    time_str=(utils.to_datetime(time_range[0]).strftime('%Y%m%d')\n",
    "              + '_'\n",
    "              + utils.to_datetime(time_range[1]).strftime('%Y%m%d'))\n",
    "    \n",
    "    for group_name,group_patt in patterns:\n",
    "        log.info(f\"Processing {group_name}, pattern: {group_patt}\")\n",
    "        chunk_dir=os.path.join(out_dir,time_str,group_name)\n",
    "        os.path.exists(chunk_dir) or os.makedirs(chunk_dir)\n",
    "  \n",
    "        # calculated on-demand in the loop below\n",
    "        @memoize.memoize()\n",
    "        def parts():\n",
    "            log.info(\"Extracting particles\")\n",
    "            result=post.query_runs(ptm_runs,\n",
    "                                   group_patt=group_patt,\n",
    "                                   time_range=time_range,\n",
    "                                   z_range=None, # not ready\n",
    "                                   max_age=np.timedelta64(max_age_days,'D'),\n",
    "                                   conc_func=post.conc_func,\n",
    "                                   grid=grid)\n",
    "            log.info(\"Adding vertical info\")\n",
    "            result=post.add_z_info(result,grid,ptm_runs)\n",
    "            return result\n",
    "        for z_name,z_range in z_ranges: \n",
    "            # Just the particles for the period, with mass, but not filtered\n",
    "            # on elevation:\n",
    "            conc_nc_fn=os.path.join(chunk_dir,f'particles-{z_name}-{max_age_days}days-{version}.nc')\n",
    "            #old_conc_nc_fn=os.path.join(chunk_dir,f'particles-{z_name}-{max_age_days}days-v02.nc')\n",
    "            #if not os.path.exists(conc_nc_fn) and os.path.exists(old_conc_nc_fn):\n",
    "            #    ds=xr.open_dataset(old_conc_nc_fn)\n",
    "            #    ds.conc.values *= 1000 # scale up to account for old code that used particles/L\n",
    "            #    ds.conc.attrs['units']='particles m-2'\n",
    "            #    ds.to_netcdf(conc_nc_fn)\n",
    "            #    ds.close()\n",
    "            #    log.info(\"Rescaled v02 output to v03\")\n",
    "            if not os.path.exists(conc_nc_fn):\n",
    "                log.info(f\"writing to {conc_nc_fn}\")\n",
    "                p=parts()\n",
    "                p=post.filter_by_z_range(p,z_range,grid,ptm_runs)\n",
    "                conc=post.particle_to_density(p,grid,normalize='area')\n",
    "                # could also use the z_bed, z_surf values to turn particle mass into\n",
    "                # a mass/z, such that normalize by area then gives a volume concentration.\n",
    "                # unless it's full water column, have to do some truncating\n",
    "                \n",
    "                # this should preserve most of the metadata\n",
    "                ds=p.copy()\n",
    "                particle_vars=[v for v in ds.variables if 'particle' in ds[v].dims]\n",
    "                for v in particle_vars:\n",
    "                    del ds[v]\n",
    "                \n",
    "                grid.write_to_xarray(ds=ds)\n",
    "                ds['conc']=('face',),conc\n",
    "                ds['conc'].attrs['units']='particles m-2'\n",
    "                \n",
    "                ds.to_netcdf(conc_nc_fn)\n",
    "                log.info(\"done writing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns=[\n",
    "    ('-0.05','.*_down50000'),\n",
    "    ('-0.005','.*_down5000'),\n",
    "    ('-0.0005','.*_down500'),\n",
    "    ('0.0','.*_none'),\n",
    "    ('0.0005','.*_up500'),\n",
    "    ('0.005','.*_up5000'),\n",
    "    ('0.05','.*_up50000')\n",
    "]\n",
    "\n",
    "z_ranges=[\n",
    "    ('bed',[0,0.5]),\n",
    "    ('surf',[-0.5,0]),\n",
    "    ('avg',[0,0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(run_date):\n",
    "    \"\"\"\n",
    "    run_date: YYYYMMDD string for start of runs\n",
    "    \"\"\"\n",
    "    ptm_runs=[post.PtmRun(run_dir=d) \n",
    "              for d in glob.glob(f\"/opt2/sfb_ocean/ptm/all_source/{run_date}/*\") ]\n",
    "    assert len(ptm_runs)==7\n",
    "    \n",
    "    # just the time period with a full field for max_age=15D\n",
    "    start=np.timedelta64(15,'D') + utils.to_dt64(datetime.datetime.strptime(run_date,'%Y%m%d'))\n",
    "\n",
    "    time_range=[start,start+np.timedelta64(15,'D')]\n",
    "    process_batch(ptm_runs,time_range,patterns,z_ranges=z_ranges)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing -0.05, pattern: .*_down50000\n",
      "INFO:root:writing to processed/20170630_20170715/-0.05/particles-bed-15days-v05.nc\n",
      "INFO:root:Extracting particles\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: sunnyvale_down50000\n",
      "INFO:root:Will skip source sunnyvale, behavior down50000, its concentration is 0\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: src001_down50000\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: petaluma_down50000\n",
      "INFO:root:Will skip source petaluma -- it's in skip_source\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: src000_down50000\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: SCLARAVCc_down50000\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: UALAMEDA_down50000\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: NAPA_down50000\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: san_jose_down50000\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: cccsd_down50000\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: fs_down50000\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: SacRiver_down50000\n",
      "INFO:root:Got SacRiver -- returning 0.0\n",
      "INFO:root:Will skip source SacRiver, behavior down50000, its concentration is 0\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: src002_down50000\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: palo_alto_down50000\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: COYOTE_down50000\n",
      "INFO:root:/opt2/sfb_ocean/ptm/all_source/20170615/w-0.05: SJRiver_down50000\n",
      "INFO:root:Got SJRiver -- returning 0.0\n",
      "INFO:root:Will skip source SJRiver, behavior down50000, its concentration is 0\n",
      "INFO:root:Adding vertical info\n",
      "INFO:UnstructuredGrid:Building point index (6035689 points)\n",
      "INFO:UnstructuredGrid:Querying point index (57124 cells)\n",
      "INFO:utils:1938274\n",
      "INFO:utils:3840978\n",
      "INFO:root:done writing\n",
      "INFO:root:writing to processed/20170630_20170715/-0.05/particles-surf-15days-v05.nc\n",
      "INFO:root:done writing\n",
      "INFO:root:writing to processed/20170630_20170715/-0.05/particles-avg-15days-v05.nc\n",
      "INFO:utils:1860564\n",
      "INFO:utils:3743841\n",
      "INFO:utils:5600633\n",
      "INFO:root:done writing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun -s cumulative process_date(\"20170615\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for d in [\"20170615\",\n",
    "          \"20170715\",\n",
    "          \"20170815\",\n",
    "          \"20170915\",\n",
    "          \"20171015\",\n",
    "          \"20171115\",\n",
    "          \"20171215\",\n",
    "          \"20180115\",\n",
    "          \"20180215\",\n",
    "          \"20180315\",\n",
    "          \"20180415\"\n",
    "         ]:\n",
    "    log.info(\"-\"*20 + d + \"-\"*20)\n",
    "    process_date(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayConcFigure(object):\n",
    "    figsize=(9,7)\n",
    "    vmin=1e-6\n",
    "    vmax=1e-2\n",
    "    zoom=(517521., 613202., 4139744., 4230105.)\n",
    "    cax_loc=[0.7,0.25,0.03,0.35]\n",
    "    num=None\n",
    "    def __init__(self,conc,**kw):\n",
    "        utils.set_keywords(self,kw)\n",
    "                    \n",
    "        self.fig=plt.figure(figsize=(10,8),num=self.num)\n",
    "        self.ax=self.fig.add_subplot(1,1,1)\n",
    "        \n",
    "        self.ccoll=grid.plot_cells(values=conc.clip(self.vmin,self.vmax),\n",
    "                                   cmap='jet',norm=colors.LogNorm(vmin=self.vmin,vmax=self.vmax),\n",
    "                                   edgecolor='face',lw=0.4,ax=self.ax)\n",
    "        self.cax=self.fig.add_axes(self.cax_loc)\n",
    "        plt.colorbar(ccoll,cax=self.cax)\n",
    "        self.ax.set_aspect('equal')\n",
    "        self.ax.xaxis.set_visible(0)\n",
    "        self.ax.yaxis.set_visible(0)\n",
    "        self.ax.axis(self.zoom)\n",
    "        self.fig.subplots_adjust(left=0.01,right=0.99,top=0.99,bottom=0.01)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
